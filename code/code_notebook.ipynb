{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsB9iOXIF6kX",
        "outputId": "23e61b20-372a-442b-84c3-dcb016b26e08"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "OBJ1_OBJ2_JSON = '/content/drive/MyDrive/cs5242_project/jsons/object1_object2.json'\n",
        "RELATIONSHIP_JSON = '/content/drive/MyDrive/cs5242_project/jsons/relationship.json'\n",
        "CAPTIONS_FILE = '/content/drive/MyDrive/cs5242_project/jsons/training_annotation.json'\n",
        "TRAIN_FEATS_DIR ='/content/drive/MyDrive/cs5242_project/extracted_feats/9_inceptionV4/train_feats/'\n",
        "TEST_FEATS = '/content/drive/MyDrive/cs5242_project/extracted_feats/9_inceptionV4/test_feats/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-ZcKXPFwox"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset,  DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eyBwfUYFwoz"
      },
      "source": [
        "with open(OBJ1_OBJ2_JSON, 'r') as obj:\n",
        "       obj1_obj2 = json.load(obj)\n",
        "with open(RELATIONSHIP_JSON, 'r') as relat:\n",
        "       relationship = json.load(relat)\n",
        "with open(CAPTIONS_FILE, 'r') as anno:\n",
        "    training_anno = json.load(anno)\n",
        "\n",
        "#Preparing Vocabulary\n",
        "relationship_vocab_stoi = relationship\n",
        "relationship_vocab_itos = {}\n",
        "for k,v in relationship_vocab_stoi.items():\n",
        "    relationship_vocab_itos[v] = k\n",
        "\n",
        "relationship_new = {}\n",
        "idx = 35\n",
        "\n",
        "for k,v in relationship.items():\n",
        "    relationship_new[k] = idx\n",
        "    idx= idx+1\n",
        "    \n",
        "vocab_stoi = {**obj1_obj2, **relationship_new}\n",
        "vocab_stoi[\"<BOS>\"] = 117\n",
        "\n",
        "\n",
        "vocab_itos = {}\n",
        "for k,v in vocab_stoi.items():\n",
        "    vocab_itos[v] = k\n",
        "\n",
        "training_anno_new ={}\n",
        "for k,v in training_anno.items():\n",
        "    training_anno_new[k] = training_anno[k]\n",
        "    training_anno_new[k][1] = vocab_stoi[relationship_vocab_itos[training_anno_new[k][1]]]  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZIg3DdaFwo1"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features_dir, training_anno_new):\n",
        "        super(MyDataset, self).__init__()\n",
        "        \n",
        "        self.features = []\n",
        "        self.captions = []\n",
        "\n",
        "        self.feat_dir = features_dir\n",
        "                \n",
        "        self.captions_file = training_anno_new\n",
        "        \n",
        "        for f in os.listdir(self.feat_dir):\n",
        "            feats = np.load(os.path.join(self.feat_dir,f))\n",
        "            self.features.append(feats)\n",
        "            self.captions.append(self.captions_file[f.split('.')[0]])\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.features[idx]), torch.tensor([117] + self.captions[idx])  \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCHLpX42Fwo1"
      },
      "source": [
        "train_dataset = MyDataset(TRAIN_FEATS_DIR, training_anno_new)\n",
        "trainloader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSJCWtdeFwo2",
        "outputId": "fef843b6-281d-41f6-aa36-f1cb1785c599"
      },
      "source": [
        "for feats, captions in trainloader:\n",
        "    print(feats.shape)\n",
        "    print(captions.shape)\n",
        "    break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 30, 1536])\n",
            "torch.Size([1, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWt2erI7xHv"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embed_size=256, hidden_size=256, num_layers=1, stacked_dropout=0, bidirectional=False, rnn='LSTM'):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(1536, embed_size)\n",
        "\n",
        "        if rnn  == 'LSTM':\n",
        "            self.rnn1 = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout = stacked_dropout)\n",
        "        if rnn  == 'GRU':\n",
        "            self.rnn1 = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout = stacked_dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "    def forward(self, features):\n",
        "        \n",
        "        features = self.fc(features) \n",
        "        \n",
        "        features = self.relu(features)\n",
        "        \n",
        "        features = self.dropout(features)\n",
        "\n",
        "        _ , hidden1 = self.rnn1(features)\n",
        "\n",
        "        return _ , hidden1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl_nvbF87zMb"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embed_size=256, hidden_size=256, num_layers=1, vocab_size=118, stacked_dropout=0, bidirectional=False, rnn='LSTM'):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        if rnn  == 'LSTM':\n",
        "            self.rnn2 = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout = stacked_dropout)\n",
        "        if rnn  == 'GRU':\n",
        "            self.rnn2 = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout = stacked_dropout)\n",
        "\n",
        "        if bidirectional:\n",
        "            self.fc = nn.Linear(hidden_size*2, vocab_size)   \n",
        "        else:\n",
        "            self.fc = nn.Linear(hidden_size, vocab_size) \n",
        "\n",
        "    \n",
        "    def forward(self, caption, hidden1):\n",
        "        \n",
        "        caption = caption.unsqueeze(dim=1)\n",
        "        \n",
        "        embedding = self.embed(caption)\n",
        "        \n",
        "        embedding = self.dropout(embedding)\n",
        "                \n",
        "        out2, hidden2 = self.rnn2(embedding, hidden1) \n",
        "\n",
        "        predictions = self.fc(out2) \n",
        "        \n",
        "        predictions = predictions.squeeze(1)\n",
        "\n",
        "        return predictions, hidden2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vkiwDhWNUW7"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = Encoder(num_layers=1, bidirectional=False, stacked_dropout=0, rnn='LSTM')\n",
        "        self.decoder = Decoder(num_layers=1, bidirectional=False, stacked_dropout=0, rnn='LSTM')\n",
        "    \n",
        "\n",
        "    def forward(self, features, caption):   \n",
        "\n",
        "        _ , hidden = self.encoder(features)\n",
        "\n",
        "        outputs = torch.zeros(3, caption.shape[0], 118)\n",
        "        \n",
        "        x = caption[:, 0]\n",
        "\n",
        "        for t in range(0, 3):\n",
        "\n",
        "            pred, hidden = self.decoder(x, hidden)\n",
        "            \n",
        "            outputs[t] = pred\n",
        "\n",
        "            _ , max_index = torch.max(pred, dim=1)\n",
        "\n",
        "            x = max_index\n",
        "\n",
        "        return outputs\n",
        "    \n",
        "    \n",
        "    def caption_image(self, features, max_length=3):\n",
        "        result_caption = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            _ , hidden1 = self.encoder(features.unsqueeze(0).to('cuda'))\n",
        "\n",
        "            top5_array = torch.zeros(3, 5)\n",
        "\n",
        "            for t in range(max_length):\n",
        "                if t==0:\n",
        "                    initial_input = torch.tensor([vocab_stoi['<BOS>']]).unsqueeze(dim=1).to('cuda')\n",
        "                    initial_input_emb = self.decoder.embed(initial_input)\n",
        "                    out2, hidden2 = self.decoder.rnn2(initial_input_emb, hidden1)\n",
        "                else:\n",
        "                    out2, hidden2 = self.decoder.rnn2(next_word_emd, hidden2)\n",
        "                    \n",
        "                output = self.decoder.fc(out2).squeeze(1)\n",
        "\n",
        "                _, top5_idxs = torch.topk(output, 5, dim=1)\n",
        "                top5_array[t] = top5_idxs\n",
        "\n",
        "                _, max_index = torch.max(output, dim=1)\n",
        "                result_caption.append(max_index.item())\n",
        "\n",
        "                next_word_emd = self.decoder.embed(max_index).unsqueeze(1)\n",
        "\n",
        "        return top5_array, [vocab_itos[idx] for idx in result_caption]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud7gWIxhENhH"
      },
      "source": [
        "model_name = 'MyModel'\n",
        "model_path = '/content/drive/MyDrive/cs5242_project/saved_models/' + model_name + '/'\n",
        "if not os.path.isdir(model_path):\n",
        "    os.mkdir(model_path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nzjLnZtFwo6"
      },
      "source": [
        "def train():\n",
        "\n",
        "    device = \"cuda\" \n",
        "    learning_rate = 3e-4\n",
        "    num_epochs = 25\n",
        "\n",
        "    model = EncoderDecoder().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch: {epoch+1}/{num_epochs}')\n",
        "\n",
        "        for idx, (features, captions) in tqdm(enumerate(trainloader), total=len(trainloader), leave=False):\n",
        "            features = features.to(device)\n",
        "            captions = captions.to(device)\n",
        "\n",
        "            outputs = model(features, captions).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = outputs.reshape(-1, outputs.shape[2])\n",
        "            captions = captions[:,1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(outputs, captions)          \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.save(model,  model_path + 'final.pth')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjY3vMMSFwo8",
        "outputId": "086cf929-fc9a-4493-a095-dc21e460880c"
      },
      "source": [
        "train()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/447 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 179.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 19/447 [00:00<00:02, 180.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 17/447 [00:00<00:02, 165.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 170.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 173.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▎         | 16/447 [00:00<00:02, 159.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 174.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 17/447 [00:00<00:02, 169.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 175.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 17/447 [00:00<00:02, 169.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 17/447 [00:00<00:02, 169.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▎         | 16/447 [00:00<00:02, 158.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 174.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 17/447 [00:00<00:02, 165.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 170.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 177.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 171.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 177.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 170.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 17/447 [00:00<00:02, 169.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 17/447 [00:00<00:02, 163.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 19/447 [00:00<00:02, 180.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 173.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 18/447 [00:00<00:02, 173.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b_vEcKVOkbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a85eb92-98ac-4c34-8194-1aa6735e8606"
      },
      "source": [
        "m = 'final.pth'\n",
        "mod = torch.load(model_path+m)\n",
        "mod.eval()\n",
        "test_feat = torch.tensor(np.load(TEST_FEATS +'000118.npy'))\n",
        "_, best = mod.caption_image(test_feat)\n",
        "print(best)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['elephant', 'stand_right', 'elephant']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poNEh35r81Nw",
        "outputId": "2c6f73af-3409-4699-a46a-c174c922dede"
      },
      "source": [
        "print(mod)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderDecoder(\n",
            "  (encoder): Encoder(\n",
            "    (relu): ReLU()\n",
            "    (fc): Linear(in_features=1536, out_features=256, bias=True)\n",
            "    (rnn1): LSTM(256, 256, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embed): Embedding(118, 256)\n",
            "    (rnn2): LSTM(256, 256, batch_first=True)\n",
            "    (fc): Linear(in_features=256, out_features=118, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3qdZZ3tJ-vM"
      },
      "source": [
        "#code to make submission CSV file\n",
        "submit_tensor=None\n",
        "for i, vid in enumerate(sorted(os.listdir(TEST_FEATS))):\n",
        "    video_feat = TEST_FEATS + vid\n",
        "    top5, _ = model.caption_image(torch.tensor(np.load(video_feat)))\n",
        "    top5 = top5.int()\n",
        "    for ix, v in enumerate(top5[1, :]):\n",
        "        if vocab_itos[v.item()] in relationship_vocab_stoi.keys():\n",
        "            top5[1, ix] = relationship_vocab_stoi[vocab_itos[v.item()]]\n",
        "        else:\n",
        "            top5[1, ix] = obj1_obj2[vocab_itos[v.item()]]\n",
        "    if i==0: \n",
        "        submit_tensor = top5\n",
        "    else:\n",
        "        submit_tensor = torch.cat((submit_tensor, top5), dim=0)\n",
        "\n",
        "px = submit_tensor.numpy()\n",
        "px = pd.DataFrame(px)\n",
        "px['label'] = px.iloc[:, 0:5].apply(lambda x: \" \".join(x.astype(str)), axis=1)\n",
        "px.drop([0, 1, 2, 3, 4], axis = 1, inplace=True)\n",
        "# px.index = np.arange(1, len(px) + 1)\n",
        "px.reset_index(inplace=True)\n",
        "px = px.rename(columns = {'index':'Id'})\n",
        "px.to_csv('/content/drive/MyDrive/cs5242_project/submissions/best_submission.csv', index=False, header=True)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}